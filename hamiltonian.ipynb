{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#!git clone https://github.com/tayfununal/hamiltonian.git"
      ],
      "metadata": {
        "id": "jMbT-c68zxI8"
      },
      "id": "jMbT-c68zxI8",
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "id": "ca7923d7",
      "metadata": {
        "id": "ca7923d7"
      },
      "outputs": [],
      "source": [
        "# Required packages\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%run hamiltonian/symplectic_euler.ipynb\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Input, Model\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "plt.style.use('seaborn-poster')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "id": "9cd9782e",
      "metadata": {
        "id": "9cd9782e"
      },
      "outputs": [],
      "source": [
        "class Hamiltonian:\n",
        "    \"Energy preserved neural network\"\n",
        "    def __init__(self, solver, input_dim, output_dim, hidden_layer, each_neuron, activation_func, epoch,\n",
        "                     batch_size, learning_rate):\n",
        "        \n",
        "        self.z, self.t, self.initial_point, self.h, self.T, self.V = solver\n",
        "\n",
        "        # Neural Network Model with MSE Loss\n",
        "        self.model = self.NN(inputs =input_dim, output=output_dim, hidden_layer=hidden_layer, neuron=each_neuron,\n",
        "                                     activation=activation_func)\n",
        "        self.model_train = self.train(model=self.model, inputs=self.t, target=self.z, learning_rate=learning_rate,\n",
        "                                    batch_size=batch_size, epochs=epoch)\n",
        "        \n",
        "        #Neural Network Model with Energy Preserved Loss\n",
        "        \n",
        "        self.energy_model = self.NN(inputs= input_dim,output=output_dim, hidden_layer=hidden_layer, neuron=each_neuron,\n",
        "                                        activation=activation_func)\n",
        "        \n",
        "        # Parametreleri atama ve veri arttÄ±rma\n",
        "        self.energy_model.set_weights(self.model_train.get_weights())\n",
        "        t_created = np.arange(float(self.initial_point[0]), float(self.initial_point[1]), 0.001)\n",
        "        target_created = self.model_train(t_created)\n",
        "        \n",
        "        self.energy_model_train = self.train(model=self.energy_model, inputs=t_created, target=target_created,\n",
        "                                             learning_rate=learning_rate, loss=self.custom_loss, batch_size=batch_size,\n",
        "                                             epochs=epoch)\n",
        "    \n",
        "    # Hamiltonian function\n",
        "\n",
        "    def H(self, T, V, q, p):\n",
        "        return T(p) + V(q)\n",
        "\n",
        "    # Neural network with MSE loss\n",
        "    def NN(self, inputs, output, hidden_layer, neuron, activation=\"relu\"):\n",
        "        np.random.seed(1)\n",
        "        tf.random.set_seed(1)\n",
        "        \n",
        "        inp = Input(shape=(inputs,), name= \"Input_Layer\")\n",
        "        for i in range(0, hidden_layer):\n",
        "            if i == 0:\n",
        "                x = Dense(neuron, activation=activation, name=\"Hidden_Layer_{}\".format(i+1))(inp)\n",
        "            else:\n",
        "                x = Dense(neuron, activation=activation, name=\"Hidden_Layer_{}\".format(i+1))(x)\n",
        "        x = Dense(output, name=\"Output_Layer\")(x)\n",
        "\n",
        "        out = tf.constant([[self.initial_point[0],self.initial_point[1]]],\n",
        "                              dtype=tf.float32) + (1-tf.math.exp(-inp**2)) * x\n",
        "\n",
        "        return Model(inputs=inp, outputs=out)\n",
        "\n",
        "    # Neural Network Model Compile and Fit\n",
        "    def train(self, model, inputs, target, learning_rate=0.01, loss=\"mse\", batch_size=32, epochs=1000):\n",
        "        \n",
        "        opt = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "        model.compile(optimizer=opt, loss=loss)\n",
        "        model.fit(x=inputs, y=target, epochs=epochs, batch_size=batch_size, shuffle=True, verbose=True)\n",
        "        \n",
        "        return model\n",
        "\n",
        "    def custom_loss(self, y_true, y_pred):\n",
        "        return tf.keras.losses.MSE(0.5, self.H(self.T, self.V, y_pred[None,:,0], y_pred[None, :,1])) +  0.001 * tf.keras.losses.MSE(y_true,y_pred)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "id": "cf358a16",
      "metadata": {
        "id": "cf358a16",
        "outputId": "76b717cd-f088-471a-cb49-bcbef2583dbc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-64-9710e2523d7b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m model = Hamiltonian(solver=symplectic_euler(T, V, initial_point=[0.,1.], t=[0,2*np.pi], h=0.5), input_dim=1, output_dim=2,\n\u001b[0;32m----> 8\u001b[0;31m             hidden_layer=20, each_neuron=32, activation_func=tf.math.sin, epoch=2000 ,batch_size=100000000, learning_rate=0.0003)\n\u001b[0m",
            "\u001b[0;32m<ipython-input-63-76801a0fe65f>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, solver, input_dim, output_dim, hidden_layer, each_neuron, activation_func, epoch, batch_size, learning_rate)\u001b[0m\n\u001b[1;32m      4\u001b[0m                      batch_size, learning_rate):\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitial_point\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mV\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msolver\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;31m# Neural Network Model with MSE Loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 6, got 5)"
          ]
        }
      ],
      "source": [
        "def T(p):\n",
        "    return (p**2)/2\n",
        "\n",
        "def V(q):\n",
        "    return (q**2)/2\n",
        "\n",
        "model = Hamiltonian(solver=symplectic_euler(T, V, initial_point=[0.,1.], t=[0,2*np.pi], h=0.5), input_dim=1, output_dim=2,\n",
        "            hidden_layer=20, each_neuron=32, activation_func=tf.math.sin, epoch=2000 ,batch_size=100000000, learning_rate=0.0003)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df26c504",
      "metadata": {
        "id": "df26c504"
      },
      "outputs": [],
      "source": [
        "model.z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa3b8733",
      "metadata": {
        "id": "aa3b8733"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize = (4, 4))\n",
        "plt.plot(model.z[:,0], model.z[:,1])\n",
        "\n",
        "test_t = np.arange(0,2*np.pi,0.01)\n",
        "prediction_energy = model.energy_model_train(test_t)\n",
        "plt.plot(prediction_energy[:,0], prediction_energy[:,1])\n",
        "\n",
        "prediction_mse = model.model_train(test_t)\n",
        "plt.plot(prediction_mse[:,0], prediction_mse[:,1])\n",
        "\n",
        "plt.plot(tf.math.sin(test_t), tf.math.cos(test_t), c=\"red\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Gut65rbS_D6x"
      },
      "id": "Gut65rbS_D6x",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}